{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main:\n",
      "  debug_bijection: false\n",
      "  compute_metrics: false\n",
      "  plot: true\n",
      "model:\n",
      "  directory: /home/fireofearth/code/data/esp_train_results/2020-11/carla_town01_B10_A5_T20_precog_SocialConvRNN\n",
      "hardware:\n",
      "  allow_growth: true\n",
      "  per_process_gpu_memory_fraction: 0.3\n",
      "images:\n",
      "  ext: jpg\n",
      "  figsize:\n",
      "  - 8\n",
      "  - 8\n",
      "split: test\n",
      "dataset:\n",
      "  plot_allchannel: false\n",
      "  class: precog.dataset.serialized_dataset.SerializedDataset\n",
      "  params:\n",
      "    root_path: /home/fireofearth/code/data/precog_carla_dataset/town01\n",
      "    _max_A: 5\n",
      "    B: 10\n",
      "    T: 20\n",
      "    T_past: 10\n",
      "    load_bev: true\n",
      "    sdt_bev: false\n",
      "    feature_pixels_per_meter: 2.0\n",
      "    W: 100\n",
      "    fmt: json\n",
      "    val_suffix: /val/\n",
      "    test_suffix: /test/\n",
      "    train_suffix: /train_generated/\n",
      "    match_prefix: ma_*\n",
      "    _name: carla_town01_A5_T20_test\n",
      "plotting:\n",
      "  bev_kwargs:\n",
      "    onechannel: false\n",
      "    allchannel: false\n",
      "    fmt: carla\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/hydra/plugins/config_source.py:190: UserWarning: \n",
      "Missing @package directive dataset/carla_town01_A5_T20_test.yaml in file:///home/fireofearth/code/robotics/precog/precog/conf.\n",
      "See https://hydra.cc/docs/next/upgrades/0.11_to_1.0/adding_a_package_directive\n",
      "  warnings.warn(message=msg, category=UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import pdb\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "import hydra\n",
    "from hydra.experimental import compose, initialize\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "from omegaconf import OmegaConf\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import precog.utils.log_util as logu\n",
    "import precog.utils.tfutil as tfutil\n",
    "import precog.interface as interface\n",
    "import precog.plotting.plot as plot\n",
    "import precog.plotting as plotting\n",
    "        \n",
    "def seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.compat.v1.set_random_seed(seed)\n",
    "seed(1234)\n",
    "\n",
    "MODEL_DIRECTORY = \"/home/fireofearth/code/data/esp_train_results/2020-11/carla_town01_B10_A5_T20_precog_SocialConvRNN\"\n",
    "overrides = [\n",
    "    \"dataset=carla_town01_A5_T20_test\",\n",
    "    \"model.directory={}\".format(MODEL_DIRECTORY),\n",
    "    \"main.compute_metrics=false\"]\n",
    "with initialize(config_path=\"precog/conf\"):\n",
    "    cfg = compose(config_name=\"esp_infer_config\", overrides=overrides)\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tfutil.create_session(\n",
    "    allow_growth=cfg.hardware.allow_growth,\n",
    "    per_process_gpu_memory_fraction=cfg.hardware.per_process_gpu_memory_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tfutil.load_annotated_model()` uses `tf.compat.v1.train.latest_checkpoint()` to get the latest TF session checkpoint; uses `tf.compat.v1.train.import_meta_graph` to recreate and restore the graph to the current TF session. \n",
    "\n",
    "Then we read the tensor collection names from disk create `tensor_collections` object by calling `tf.compat.v1.get_collection()`  on the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/fireofearth/code/data/esp_train_results/2020-11/carla_town01_B10_A5_T20_precog_SocialConvRNN/esp-model-15000\n"
     ]
    }
   ],
   "source": [
    "ckpt, graph, tensor_collections = tfutil.load_annotated_model(cfg.model.directory, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'global_step:0' shape=() dtype=int64_ref>\n",
      "15000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'H_pq:0' shape=(10, 12) dtype=float64>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "print(global_step)\n",
    "step = sess.run(global_step)\n",
    "print(step)\n",
    "\n",
    "criterion = tf.get_default_graph().get_tensor_by_name(\"H_pq:0\")\n",
    "Hpq = tf.get_default_graph().get_tensor_by_name(\"H_pq:0\")\n",
    "ehat = tf.get_default_graph().get_tensor_by_name(\"ehat:0\")\n",
    "# model_distribution.variables\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.training.rmsprop.RMSPropOptimizer object at 0x7f5b2a8884a8>\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.compat.v1.train.RMSPropOptimizer(4e-4)\n",
    "print(optimizer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RMSPropOptimizer' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-332c5c500a2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RMSPropOptimizer' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "print(optimizer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input\n",
      "   S_past_world_frame:0 yaws:0 overhead_features:0 agent_presence:0 light_strings:0 is_training:0 Z_sample:0\n",
      "\n",
      "infer_input\n",
      "   S_past_world_frame:0 yaws:0 overhead_features:0 agent_presence:0 light_strings:0 S_future_world_frame:0 is_training:0\n",
      "\n",
      "shared_input\n",
      "   agent_presence:0 is_training:0 light_strings:0 yaws:0 S_past_world_frame:0 overhead_features:0\n",
      "\n",
      "sample_output\n",
      "   Z:0 mu:0 S_grid_frame:0 S_world_frame:0 m:0 sigma:0 S_car_frames:0 sigel:0 log_q_samples:0\n",
      "\n",
      "infer_output\n",
      "   log_q_expert:0\n",
      "\n",
      "sample_metric\n",
      "   mean_MHat:0 mean_Hqphat:0 mhat:0\n",
      "\n",
      "infer_metric\n",
      "   mean_Hpq:0 mean_ehat:0 H_pq:0 ehat:0\n",
      "\n",
      "intermediate_input\n",
      "   S_past_car_frames:0 S_past_grid_frame:0 agent_counts:0\n",
      "\n",
      "intermediate_label\n",
      "   S_future_car_frames:0 S_future_grid_frame:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, coll in tensor_collections.items():\n",
    "    print(name)\n",
    "    o = '   ' + ' '.join(map(lambda t: t.name, coll))\n",
    "    print(o)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# print out the graph\n",
    "# print(graph.get_operations())\n",
    "\n",
    "# operations = graph.get_operations()\n",
    "# for op in operations:\n",
    "#     print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interface that contains and is used to run the trained model\n",
    "inference = interface.ESPInference(tensor_collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = hydra.utils.instantiate(cfg.dataset, **cfg.dataset.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a minibatch from the dataset\n",
    "minibatch = dataset.get_minibatch(\n",
    "    split=cfg.split,\n",
    "    input_singleton=inference.training_input,\n",
    "    is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can use tensorboard to display the computation graph when running the network\n",
    "# the graph is very messy. To read it call\n",
    "# tensorboard --logdir=./log\n",
    "# writer = tf.summary.FileWriter(\"log\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the latent variables used in the ESP network\n",
    "# prepare to run the TF session with minibatch as input\n",
    "sessrun = functools.partial(sess.run, feed_dict=minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the latent variables used in the ESP network\n",
    "base_and_log_q = inference.base_and_log_q.to_numpy(sessrun)\n",
    "print(base_and_log_q.Z_sample.shape)\n",
    "print(base_and_log_q.Z_sample[0,0,0,0,:])\n",
    "\n",
    "# sampled latent variables for trained networks have dimensions (10, 12, 5, 20, 2)\n",
    "# and are randomly sampled at every call within the graph as evident from below\n",
    "# [1.03849122   1.23841257]\n",
    "# [-0.02836075 -0.10323571]\n",
    "# [-0.06120932 -0.65453399]\n",
    "# [1.29992859   0.30881844]\n",
    "# ... etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the latent variables used in the ESP network\n",
    "# from the model's variables themselves, bypassing the interface\n",
    "coll = tensor_collections\n",
    "Z_sample = coll['sample_input'][6]\n",
    "print(Z_sample)\n",
    "o = sessrun(Z_sample)\n",
    "print(o.shape)\n",
    "print(o[0,0,0,0,:])\n",
    "# for k, v in tensor_collections.items():\n",
    "#     print(k)\n",
    "#     print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that S_past_world_frame is loaded from past trajectory\n",
    "coll = tensor_collections\n",
    "S_past_world_frame = coll['sample_input'][0]\n",
    "o = sessrun(S_past_world_frame)\n",
    "print(o.shape)\n",
    "print(o[0,0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that S_past_world_frame is loaded from past trajectory\n",
    "# using Tensor.eval() instead\n",
    "coll = tensor_collections\n",
    "Z_sample = coll['sample_input'][6]\n",
    "print(Z_sample)\n",
    "o = Z_sample.eval(session=sess)#, feed_dict=minibatch)\n",
    "print(o.shape)\n",
    "print(o[0,0,0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll = tensor_collections\n",
    "S_grid_frame = coll['sample_output'][2]\n",
    "o = Z_sample.eval(session=sess, feed_dict=minibatch)\n",
    "print(o.shape)\n",
    "print(o[0,0,0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, _ in minibatch.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = tfp.distributions.MultivariateNormalDiag(\n",
    "            loc=tf.constant(0., dtype=tf.float64), scale_diag=tf.constant([1., 1.], dtype=tf.float64))\n",
    "sample = distribution.sample(\n",
    "    sample_shape=(\n",
    "        inference.metadata.B, \n",
    "        inference.metadata.K, \n",
    "        inference.metadata.A, \n",
    "        inference.metadata.T))\n",
    "sample = sess.run(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally figured out how to fix the normal sampling\n",
    "coll = tensor_collections\n",
    "Z_sample = coll['sample_input'][6]\n",
    "Z = coll['sample_output'][0]\n",
    "o1, o2 = sess.run([Z, Z_sample], feed_dict={Z_sample: sample})\n",
    "print(o1.shape)\n",
    "print(o1[0,0,0,0,:])\n",
    "print(o2[0,0,0,0,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
