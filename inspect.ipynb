{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main:\n",
      "  debug_bijection: false\n",
      "  compute_metrics: false\n",
      "  plot: true\n",
      "model:\n",
      "  directory: /home/fireofearth/code/data/esp_train_results/2020-11/carla_town01_B10_A5_T20_precog_SocialConvRNN\n",
      "hardware:\n",
      "  allow_growth: true\n",
      "  per_process_gpu_memory_fraction: 0.3\n",
      "images:\n",
      "  ext: jpg\n",
      "  figsize:\n",
      "  - 8\n",
      "  - 8\n",
      "split: test\n",
      "dataset:\n",
      "  plot_allchannel: false\n",
      "  class: precog.dataset.serialized_dataset.SerializedDataset\n",
      "  params:\n",
      "    root_path: /home/fireofearth/code/data/precog_carla_dataset/town01\n",
      "    _max_A: 5\n",
      "    B: 10\n",
      "    T: 20\n",
      "    T_past: 10\n",
      "    load_bev: true\n",
      "    sdt_bev: false\n",
      "    feature_pixels_per_meter: 2.0\n",
      "    W: 100\n",
      "    fmt: json\n",
      "    train_suffix: /train/\n",
      "    val_suffix: /val/\n",
      "    test_suffix: /test_experiment_0/\n",
      "    match_prefix: ma_*\n",
      "    _name: carla_town01_A5_T20_test\n",
      "plotting:\n",
      "  bev_kwargs:\n",
      "    onechannel: false\n",
      "    allchannel: false\n",
      "    fmt: carla\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/hydra/plugins/config_source.py:190: UserWarning: \n",
      "Missing @package directive dataset/carla_town01_A5_T20_test.yaml in file:///home/fireofearth/code/robotics/precog/precog/conf.\n",
      "See https://hydra.cc/docs/next/upgrades/0.11_to_1.0/adding_a_package_directive\n",
      "  warnings.warn(message=msg, category=UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import pdb\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "import hydra\n",
    "from hydra.experimental import compose, initialize\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "from omegaconf import OmegaConf\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import precog.utils.log_util as logu\n",
    "import precog.utils.tfutil as tfutil\n",
    "import precog.interface as interface\n",
    "import precog.plotting.plot as plot\n",
    "import precog.plotting as plotting\n",
    "        \n",
    "def seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.compat.v1.set_random_seed(seed)\n",
    "seed(1234)\n",
    "\n",
    "MODEL_DIRECTORY = \"/home/fireofearth/code/data/esp_train_results/2020-11/carla_town01_B10_A5_T20_precog_SocialConvRNN\"\n",
    "overrides = [\n",
    "    \"dataset=carla_town01_A5_T20_test\",\n",
    "    \"model.directory={}\".format(MODEL_DIRECTORY),\n",
    "    \"main.compute_metrics=false\"]\n",
    "with initialize(config_path=\"precog/conf\"):\n",
    "    cfg = compose(config_name=\"esp_infer_config\", overrides=overrides)\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tfutil.create_session(\n",
    "    allow_growth=cfg.hardware.allow_growth,\n",
    "    per_process_gpu_memory_fraction=cfg.hardware.per_process_gpu_memory_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/fireofearth/code/data/esp_train_results/2020-11/carla_town01_B10_A5_T20_precog_SocialConvRNN/esp-model-15000\n"
     ]
    }
   ],
   "source": [
    "ckpt, graph, tensor_collections = tfutil.load_annotated_model(cfg.model.directory, sess)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# print out the graph\n",
    "# print(graph.get_operations())\n",
    "\n",
    "# operations = graph.get_operations()\n",
    "# for op in operations:\n",
    "#     print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interface that contains and is used to run the trained model\n",
    "inference = interface.ESPInference(tensor_collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/hydra/_internal/utils.py:632: UserWarning: \n",
      "Config key 'class' is deprecated since Hydra 1.0 and will be removed in Hydra 1.1.\n",
      "Use '_target_' instead of 'class'.\n",
      "See https://hydra.cc/docs/next/upgrades/0.11_to_1.0/object_instantiation_changes\n",
      "  warnings.warn(message=msg, category=UserWarning)\n",
      "/home/fireofearth/miniconda3/envs/precog/lib/python3.6/site-packages/hydra/_internal/utils.py:577: UserWarning: \n",
      "Field 'params' is deprecated since Hydra 1.0 and will be removed in Hydra 1.1.\n",
      "Inline the content of params directly at the containing node.\n",
      "See https://hydra.cc/docs/next/upgrades/0.11_to_1.0/object_instantiation_changes\n",
      "  warnings.warn(category=UserWarning, message=msg)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset = hydra.utils.instantiate(cfg.dataset, **cfg.dataset.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a minibatch from the dataset\n",
    "minibatch = dataset.get_minibatch(\n",
    "    split=cfg.split,\n",
    "    input_singleton=inference.training_input,\n",
    "    is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can use tensorboard to display the computation graph when running the network\n",
    "# the graph is very messy. To read it call\n",
    "# tensorboard --logdir=./log\n",
    "# writer = tf.summary.FileWriter(\"log\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the latent variables used in the ESP network\n",
    "# prepare to run the TF session with minibatch as input\n",
    "sessrun = functools.partial(sess.run, feed_dict=minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 12, 5, 20, 2)\n",
      "[-1.39158847  0.44136089]\n"
     ]
    }
   ],
   "source": [
    "# generate the latent variables used in the ESP network\n",
    "base_and_log_q = inference.base_and_log_q.to_numpy(sessrun)\n",
    "print(base_and_log_q.Z_sample.shape)\n",
    "print(base_and_log_q.Z_sample[0,0,0,0,:])\n",
    "\n",
    "# sampled latent variables for trained networks have dimensions (10, 12, 5, 20, 2)\n",
    "# and are randomly sampled at every call within the graph as evident from below\n",
    "# [1.03849122   1.23841257]\n",
    "# [-0.02836075 -0.10323571]\n",
    "# [-0.06120932 -0.65453399]\n",
    "# [1.29992859   0.30881844]\n",
    "# ... etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Z_sample:0\", shape=(10, 12, 5, 20, 2), dtype=float64)\n",
      "(10, 12, 5, 20, 2)\n",
      "[-0.97522718  0.13964392]\n"
     ]
    }
   ],
   "source": [
    "# generate the latent variables used in the ESP network\n",
    "# from the model's variables themselves, bypassing the interface\n",
    "coll = tensor_collections\n",
    "Z_sample = coll['sample_input'][6]\n",
    "print(Z_sample)\n",
    "o = sessrun(Z_sample)\n",
    "print(o.shape)\n",
    "print(o[0,0,0,0,:])\n",
    "# for k, v in tensor_collections.items():\n",
    "#     print(k)\n",
    "#     print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 10, 2)\n",
      "[-5.14070564  0.02072373]\n"
     ]
    }
   ],
   "source": [
    "# check that S_past_world_frame is loaded from past trajectory\n",
    "coll = tensor_collections\n",
    "S_past_world_frame = coll['sample_input'][0]\n",
    "o = sessrun(S_past_world_frame)\n",
    "print(o.shape)\n",
    "print(o[0,0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Z_sample:0\", shape=(10, 12, 5, 20, 2), dtype=float64)\n",
      "(10, 12, 5, 20, 2)\n",
      "[-1.24676215 -0.56641227]\n"
     ]
    }
   ],
   "source": [
    "# check that S_past_world_frame is loaded from past trajectory\n",
    "# using Tensor.eval() instead\n",
    "coll = tensor_collections\n",
    "Z_sample = coll['sample_input'][6]\n",
    "print(Z_sample)\n",
    "o = Z_sample.eval(session=sess)#, feed_dict=minibatch)\n",
    "print(o.shape)\n",
    "print(o[0,0,0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 12, 5, 20, 2)\n",
      "[ 0.28704478 -0.1457633 ]\n"
     ]
    }
   ],
   "source": [
    "coll = tensor_collections\n",
    "S_grid_frame = coll['sample_output'][2]\n",
    "o = Z_sample.eval(session=sess, feed_dict=minibatch)\n",
    "print(o.shape)\n",
    "print(o[0,0,0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"S_past_world_frame:0\", shape=(10, 5, 10, 2), dtype=float64)\n",
      "Tensor(\"yaws:0\", shape=(10, 5), dtype=float64)\n",
      "Tensor(\"overhead_features:0\", shape=(10, 100, 100, 4), dtype=float64)\n",
      "Tensor(\"agent_presence:0\", shape=(10, 5), dtype=float64)\n",
      "Tensor(\"light_strings:0\", shape=(10,), dtype=string)\n",
      "Tensor(\"S_future_world_frame:0\", shape=(10, 5, 20, 2), dtype=float64)\n",
      "Tensor(\"is_training:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "for k, _ in minibatch.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = tfp.distributions.MultivariateNormalDiag(\n",
    "            loc=tf.constant(0., dtype=tf.float64), scale_diag=tf.constant([1., 1.], dtype=tf.float64))\n",
    "sample = distribution.sample(\n",
    "    sample_shape=(\n",
    "        inference.metadata.B, \n",
    "        inference.metadata.K, \n",
    "        inference.metadata.A, \n",
    "        inference.metadata.T))\n",
    "sample = sess.run(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 12, 5, 20, 2)\n",
      "[ 1.29657744 -0.85608509]\n",
      "[ 1.29657744 -0.85608509]\n"
     ]
    }
   ],
   "source": [
    "# finally figured out how to fix the normal sampling\n",
    "coll = tensor_collections\n",
    "Z_sample = coll['sample_input'][6]\n",
    "Z = coll['sample_output'][0]\n",
    "o1, o2 = sess.run([Z, Z_sample], feed_dict={Z_sample: sample})\n",
    "print(o1.shape)\n",
    "print(o1[0,0,0,0,:])\n",
    "print(o2[0,0,0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
